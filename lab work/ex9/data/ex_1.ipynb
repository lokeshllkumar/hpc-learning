{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIkrsN5BWAID",
        "outputId": "600b6129-1db5-4e6a-9116-5e2f4baae9e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 22 05:03:13 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJNHqc-o2cGw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXFXbd_WWEEe",
        "outputId": "56408ad1-2a35-400a-8bca-d959abc7709f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz4SMYn4SxmZ",
        "outputId": "39624559-ea75-4055-e9ae-19bc35df8a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 19507, done.\u001b[K\n",
            "remote: Counting objects: 100% (4922/4922), done.\u001b[K\n",
            "remote: Compressing objects: 100% (658/658), done.\u001b[K\n",
            "remote: Total 19507 (delta 4565), reused 4336 (delta 4264), pack-reused 14585 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19507/19507), 133.38 MiB | 16.97 MiB/s, done.\n",
            "Resolving deltas: 100% (17225/17225), done.\n",
            "Updating files: 100% (4026/4026), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO0Z6Gd5Um7S",
        "outputId": "1d5781aa-1cc5-4067-b9d6-7d3c652a8b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc -ccbin g++ -I../../../Common -m64 --threads 0 --std=c++11 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../../bin/x86_64/linux/release\n"
          ]
        }
      ],
      "source": [
        "!cd cuda-samples/Samples/1_Utilities/deviceQuery && make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dqe8QhuUtUT",
        "outputId": "ad25e394-b979-42cb-bcaa-d73c6148542d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deviceQuery\t deviceQuery_vs2017.sln      deviceQuery_vs2019.vcxproj  Makefile\n",
            "deviceQuery.cpp  deviceQuery_vs2017.vcxproj  deviceQuery_vs2022.sln\t NsightEclipse.xml\n",
            "deviceQuery.o\t deviceQuery_vs2019.sln      deviceQuery_vs2022.vcxproj  README.md\n",
            "cuda-samples/Samples/1_Utilities/deviceQuery/./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          12.2 / 12.2\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15102 MBytes (15835660288 bytes)\n",
            "  (040) Multiprocessors, (064) CUDA Cores/MP:    2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total shared memory per multiprocessor:        65536 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.2, CUDA Runtime Version = 12.2, NumDevs = 1\n",
            "Result = PASS\n"
          ]
        }
      ],
      "source": [
        "!cd cuda-samples/Samples/1_Utilities/deviceQuery && ls\n",
        "!cuda-samples/Samples/1_Utilities/deviceQuery/./deviceQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwsdgr2wUvtY",
        "outputId": "5bd2dd58-b6f3-426f-80b9-b1fb52948d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL502K4GUziy",
        "outputId": "a021e9e4-6b5e-4864-d054-e80e3a0a5007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp2tzp3407\".\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWxD_avdUJ2d",
        "outputId": "1e94f2ee-2bec-40a1-9e0a-ecfd7d793247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 elements of the output array:\n",
            "2 2 2 2 2 2 2 2 2 2 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void brightKernel(float *d_Pin, float *d_Pout, int n, int m) {\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if ((Row < m) && (Col < n)) {\n",
        "        d_Pout[Row * n + Col] = 2 * d_Pin[Row * n + Col];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1024;\n",
        "    int m = 1024;\n",
        "\n",
        "    // Allocate host memory\n",
        "    size_t size = n * m * sizeof(float);\n",
        "    float *h_Pin = (float *)malloc(size);\n",
        "    float *h_Pout = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < n * m; ++i) {\n",
        "        h_Pin[i] = static_cast<float>(1);\n",
        "    }\n",
        "\n",
        "    float *d_Pin, *d_Pout;\n",
        "    cudaMalloc(&d_Pin, size);\n",
        "    cudaMalloc(&d_Pout, size);\n",
        "\n",
        "    cudaMemcpy(d_Pin, h_Pin, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockDim(8, 4);\n",
        "    dim3 gridDim((n + blockDim.x - 1) / blockDim.x, (m + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    brightKernel<<<gridDim, blockDim>>>(d_Pin, d_Pout, n, m);\n",
        "\n",
        "    cudaMemcpy(h_Pout, d_Pout, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"First 10 elements of the output array:\\n\";\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        cout << h_Pout[i] << \" \";\n",
        "    }\n",
        "    cout << \"\\n\";\n",
        "\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < n * m; ++i) {\n",
        "        if (h_Pout[i] != 2 * h_Pin[i]) {\n",
        "            success = false;\n",
        "            cout << \"Mismatch at index \" << i << \"\\n\";\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (!success) {\n",
        "        std::cout << \"Kernel executed failed.\\n\";\n",
        "    }\n",
        "\n",
        "    cudaFree(d_Pin);\n",
        "    cudaFree(d_Pout);\n",
        "\n",
        "    free(h_Pin);\n",
        "    free(h_Pout);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZXKrW1t3X8s"
      },
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}