{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIkrsN5BWAID",
        "outputId": "c177d47d-2429-490a-c25f-68d87cefe99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 29 04:06:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJNHqc-o2cGw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXFXbd_WWEEe",
        "outputId": "29804f11-6bff-4d89-d1af-7d40e48dfc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz4SMYn4SxmZ",
        "outputId": "46f20a7a-b0f7-4b59-83b1-d39fc469c23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 19507, done.\u001b[K\n",
            "remote: Counting objects: 100% (4922/4922), done.\u001b[K\n",
            "remote: Compressing objects: 100% (658/658), done.\u001b[K\n",
            "remote: Total 19507 (delta 4565), reused 4336 (delta 4264), pack-reused 14585 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19507/19507), 133.38 MiB | 19.39 MiB/s, done.\n",
            "Resolving deltas: 100% (17225/17225), done.\n",
            "Updating files: 100% (4026/4026), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO0Z6Gd5Um7S",
        "outputId": "5639ea18-4fc0-4964-a861-836c5f1ab3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc -ccbin g++ -I../../../Common -m64 --threads 0 --std=c++11 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../../bin/x86_64/linux/release\n"
          ]
        }
      ],
      "source": [
        "!cd cuda-samples/Samples/1_Utilities/deviceQuery && make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dqe8QhuUtUT",
        "outputId": "ec090044-ec6e-4309-e157-f24e9a05eafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deviceQuery\t deviceQuery_vs2017.sln      deviceQuery_vs2019.vcxproj  Makefile\n",
            "deviceQuery.cpp  deviceQuery_vs2017.vcxproj  deviceQuery_vs2022.sln\t NsightEclipse.xml\n",
            "deviceQuery.o\t deviceQuery_vs2019.sln      deviceQuery_vs2022.vcxproj  README.md\n",
            "cuda-samples/Samples/1_Utilities/deviceQuery/./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          12.2 / 12.2\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15102 MBytes (15835660288 bytes)\n",
            "  (040) Multiprocessors, (064) CUDA Cores/MP:    2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total shared memory per multiprocessor:        65536 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.2, CUDA Runtime Version = 12.2, NumDevs = 1\n",
            "Result = PASS\n"
          ]
        }
      ],
      "source": [
        "!cd cuda-samples/Samples/1_Utilities/deviceQuery && ls\n",
        "!cuda-samples/Samples/1_Utilities/deviceQuery/./deviceQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwsdgr2wUvtY",
        "outputId": "4fa0f839-c615-489d-ccdc-03665920e4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL502K4GUziy",
        "outputId": "f5299812-b5b7-4e30-9cc2-1cbb0ebb8026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpsen2gtls\".\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWxD_avdUJ2d",
        "outputId": "e89136b4-8b13-46a2-8768-d581d94f31b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Matrix:\n",
            "1 2 3 4 \n",
            "5 6 7 8 \n",
            "9 10 11 12 \n",
            "13 14 15 16 \n",
            "Transposed Matrix:\n",
            "1 5 9 13 \n",
            "2 6 10 14 \n",
            "3 7 11 15 \n",
            "4 8 12 16 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define TILE_SIZE 32\n",
        "\n",
        "__global__ void matrixTransposeSharedMemory(float *input, float *output, int N) {\n",
        "    __shared__ float tile[TILE_SIZE][TILE_SIZE + 1];\n",
        "\n",
        "    int x = blockIdx.x * TILE_SIZE + threadIdx.x;\n",
        "    int y = blockIdx.y * TILE_SIZE + threadIdx.y;\n",
        "\n",
        "    if (x < N && y < N) {\n",
        "        tile[threadIdx.y][threadIdx.x] = input[y * N + x];\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    x = blockIdx.y * TILE_SIZE + threadIdx.x;\n",
        "    y = blockIdx.x * TILE_SIZE + threadIdx.y;\n",
        "\n",
        "    if (x < N && y < N) {\n",
        "        output[y * N + x] = tile[threadIdx.x][threadIdx.y];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 4;\n",
        "    float *matrix = new float[N * N];\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            matrix[i * N + j] = static_cast<float>(i * N + j + 1);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"Original Matrix:\" << std::endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            std::cout << matrix[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    float *d_input, *d_output;\n",
        "    cudaMalloc(&d_input, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_output, N * N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_input, matrix, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockSize(TILE_SIZE, TILE_SIZE);\n",
        "    dim3 gridSize((N + TILE_SIZE - 1) / TILE_SIZE, (N + TILE_SIZE - 1) / TILE_SIZE);\n",
        "\n",
        "    matrixTransposeSharedMemory<<<gridSize, blockSize>>>(d_input, d_output, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    float *transposedMatrix = new float[N * N];\n",
        "    cudaMemcpy(transposedMatrix, d_output, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"Transposed Matrix:\" << std::endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            std::cout << transposedMatrix[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    delete[] matrix;\n",
        "    delete[] transposedMatrix;\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZXKrW1t3X8s"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}